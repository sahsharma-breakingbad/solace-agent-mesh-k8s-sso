apiVersion: v1
kind: ConfigMap
metadata:
  name: solace-agent-mesh-config
data:
  logging_config.ini: |
    [loggers]
    keys=root,LiteLLM,py_warnings,solace_ai_connector,uvicorn,uvicorn_error,uvicorn_access
    [handlers]
    keys=streamHandler,rotatingFileHandler
    [formatters]
    keys=simpleFormatter
    [logger_root]
    level=DEBUG
    handlers=streamHandler,rotatingFileHandler
    qualname=root
    [handler_streamHandler]
    class=StreamHandler
    level=INFO
    formatter=simpleFormatter
    args=(sys.stdout,)
    [logger_LiteLLM]
    level=DEBUG
    handlers=streamHandler,rotatingFileHandler
    qualname=LiteLLM
    propagate=0
    [logger_py_warnings]
    level=WARNING
    handlers=streamHandler,rotatingFileHandler
    qualname=py.warnings
    propagate=0
    [logger_solace_ai_connector]
    level=DEBUG
    handlers=streamHandler,rotatingFileHandler
    qualname=solace_ai_connector
    propagate=0
    [logger_uvicorn]
    level=DEBUG
    handlers=streamHandler,rotatingFileHandler
    qualname=uvicorn
    propagate=0
    [logger_uvicorn_error]
    level=INFO
    handlers=streamHandler,rotatingFileHandler
    qualname=uvicorn.error
    propagate=0
    [logger_uvicorn_access]
    level=INFO
    handlers=streamHandler,rotatingFileHandler
    qualname=uvicorn.access
    propagate=0
    [handler_rotatingFileHandler]
    class=logging.handlers.RotatingFileHandler
    level=DEBUG
    formatter=simpleFormatter
    args=('sam.log', 'a', 52428800, 10)
    [formatter_simpleFormatter]
    format=%(asctime)s - %(name)s - %(levelname)s - %(message)s
  shared_config.yaml: |
    shared_config:
      - broker_connection: &broker_connection
          dev_mode: ${SOLACE_DEV_MODE, false}
          broker_url: ${SOLACE_BROKER_URL, ws://localhost:8080}
          broker_username: ${SOLACE_BROKER_USERNAME, default}
          broker_password: ${SOLACE_BROKER_PASSWORD, default}
          broker_vpn: ${SOLACE_BROKER_VPN, default}
          temporary_queue: ${USE_TEMPORARY_QUEUES, true}
      - models:
        planning: &planning_model
          model: ${LLM_SERVICE_PLANNING_MODEL_NAME}
          api_base: ${LLM_SERVICE_ENDPOINT}
          api_key: ${LLM_SERVICE_API_KEY}
        general: &general_model
          model: ${LLM_SERVICE_GENERAL_MODEL_NAME}
          api_base: ${LLM_SERVICE_ENDPOINT}
          api_key: ${LLM_SERVICE_API_KEY}
        image_gen: &image_generation_model
          model: ${IMAGE_MODEL_NAME}
          api_base: ${IMAGE_SERVICE_ENDPOINT}
          api_key: ${IMAGE_SERVICE_API_KEY}
        report_gen: &report_generation_model
          model: ${LLM_REPORT_MODEL_NAME}
          api_base: ${LLM_SERVICE_ENDPOINT}
          api_key: ${LLM_SERVICE_API_KEY}
        multimodal: &multimodal_model  "gemini-2.5-flash-preview-04-17"
        gemini_pro: &gemini_pro_model "gemini-2.5-pro-exp-03-25"
      - services:
        session_service: &default_session_service
          type: "memory"
          default_behavior: "PERSISTENT"
        artifact_service: &default_artifact_service
          type: "filesystem"
          base_path: "/tmp/samv2"
          artifact_scope: namespace
        data_tools_config: &default_data_tools_config
          sqlite_memory_threshold_mb: 100
          max_result_preview_rows: 50
          max_result_preview_bytes: 4096
  main_orchestrator.yaml: |
    # Solace Agent Mesh Orchestrator Agent Configurations
    log:
      stdout_log_level: INFO
      log_file_level: INFO
      log_file: orchestrator-agent.log
    # Shared SAM config
    !include shared_config.yaml
    apps:
      - name: orchestrator-agent_app
        app_base_path: .
        app_module: solace_agent_mesh.agent.sac.app
        broker:
          <<: *broker_connection
        app_config:
          namespace: ${NAMESPACE}
          supports_streaming: true
          agent_name: "OrchestratorAgent"
          display_name: "OrchestratorAgent"
          model: *planning_model
          instruction: |
            You are the Orchestrator Agent within an AI agentic system. Your primary responsibilities are to:
            1. Process tasks received from external sources via the system Gateway.
            2. Analyze each task to determine the optimal execution strategy:
               a. Single Agent Delegation: If the task can be fully addressed by a single peer agent (based on their declared capabilities/description), delegate the task to that agent.
               b. Multi-Agent Coordination: If task completion requires a coordinated effort from multiple peer agents: first, devise a logical execution plan (detailing the sequence of agent invocations and any necessary data handoffs). Then, manage the execution of this plan, invoking each agent in the defined order.
               c. Direct Execution: If the task is not suitable for delegation (neither to a single agent nor a multi-agent sequence) and falls within your own capabilities, execute the task yourself.
            Artifact Management Guidelines:
            - If an artifact was created during the task (either by yourself or a delegated agent), you must use the `list_artifacts` tool to get the details of the created artifacts.
            - You must then review the list of artifacts and return the ones that are important for the user by using the `signal_artifact_for_return` tool.
            - Provide regular progress updates using `status_update` embed directives, especially before initiating any tool call.
          inject_system_purpose: true
          inject_response_format: true
          inject_user_profile: true
          session_service: *default_session_service
          artifact_service: *default_artifact_service
          artifact_handling_mode: "embed"
          enable_embed_resolution: true
          enable_artifact_content_instruction: true
          data_tools_config: *default_data_tools_config
          tools:
            - group_name: artifact_management
              tool_type: builtin-group
            - tool_type: builtin-group
              group_name: "data_analysis"
          agent_card:
            description: "The Orchestrator component. It manages tasks and coordinates multi-agent workflows."
            defaultInputModes: [text]
            defaultOutputModes: [text, file]
            skills: []
          agent_card_publishing:
            interval_seconds: 10
          agent_discovery:
            enabled: true
          inter_agent_communication:
            allow_list: ["*"]
            request_timeout_seconds: 600
  webui.yaml: |
    # Solace Agent Mesh WebUI Gateway Configuration
    log:
      stdout_log_level: INFO
      log_file_level: DEBUG
      log_file: webui_app.log
    # Shared SAM config
    !include shared_config.yaml
    apps:
      - name: a2a_webui_app
        app_base_path: .
        app_module: solace_agent_mesh.gateway.http_sse.app
        broker:
          <<: *broker_connection
        app_config:
          namespace: ${NAMESPACE}
          session_secret_key: ${SESSION_SECRET_KEY}
          artifact_service: *default_artifact_service
          gateway_id: ${WEBUI_GATEWAY_ID}
          fastapi_host: ${FASTAPI_HOST}
          fastapi_port: ${FASTAPI_PORT}
          cors_allowed_origins: # List of allowed origins for CORS
            - "http://localhost:3000" # Example: Allow local React dev server
            - "http://127.0.0.1:3000"
            # Add other origins as needed, or use ["*"] for wide open (less secure)
          enable_embed_resolution: ${ENABLE_EMBED_RESOLUTION} # Enable late-stage resolution
          gateway_artifact_content_limit_bytes: ${GATEWAY_ARTIFACT_LIMIT_BYTES, 10000000} # Max size for late-stage embeds
          sse_max_queue_size: ${SSE_MAX_QUEUE_SIZE, 200} # Max size of SSE connection queues
          system_purpose: >
                The system is an AI Chatbot with agentic capabilities.
                It will use the agents available to provide information,
                reasoning and general assistance for the users in this system.
                **Always return useful artifacts and files that you create to the user.**
                Provide a status update before each tool call.
                Your external name is Agent Mesh.
          response_format: >
                Responses should be clear, concise, and professionally toned.
                Format responses to the user in Markdown using appropriate formatting.
          # --- Frontend Config Passthrough ---
          frontend_welcome_message: >
          frontend_bot_name: Solace Agent Mesh
          frontend_collect_feedback: false  
  core_agents.yaml: |
    log:
      stdout_log_level: INFO
      log_file_level: DEBUG # Changed from INFO to DEBUG to capture ADK INFO logs
      log_file: a2a_agents.log

    # Shared SAM config
    !include ../shared_config.yaml

    apps:
    # ---  Markitdown Agent ---
      - name: markitdown_agent_app
        app_base_path: .
        app_module: solace_agent_mesh.agent.sac.app
        broker:
          <<: *broker_connection

        # --- App Level Config ---
        app_config:
          namespace: ${NAMESPACE}
          supports_streaming: true
          agent_name: "MarkitdownAgent"
          display_name: "Markdown Creator"
          model: *multimodal_model # Or *planning_model, choose as appropriate
          instruction: |
            The MarkitdownAgent has the following capability:
            * convert various file types (like PDF, DOCX, XLSX, HTML, CSV, PPTX, ZIP) to Markdown.
            Any files you get that might be useful should be saved using create_artifact.
            There is no need to provide a preview of the content in the response.

          # --- Tools Definition ---
          tools:
            - tool_type: builtin
              tool_name: "convert_file_to_markdown"
            - tool_type: builtin-group
              group_name: "artifact_management"

          session_service:
            type: "memory"
            default_behavior: "PERSISTENT" # Or "RUN_BASED"

          artifact_service:
            type: "filesystem"
            base_path: "/tmp/samv2"
            artifact_scope: namespace
          artifact_handling_mode: "reference"
          enable_embed_resolution: true
          enable_artifact_content_instruction: true

          # --- Agent Card Definition ---
          agent_card:
            description: "An agent that converts various file types (like PDF, DOCX, XLSX, HTML, CSV, PPTX, ZIP) to Markdown format."
            defaultInputModes: ["text", "file"] # Can take files as input
            defaultOutputModes: ["text", "file"] # Outputs markdown file
            skills:
            - id: "convert_file_to_markdown"
              name: "Markdown Converter"
              description: "Converts various file types to Markdown format."

          # --- Discovery & Communication ---
          agent_card_publishing: { interval_seconds: 10 }
          agent_discovery: { enabled: false }
          inter_agent_communication:
            allow_list: []
            request_timeout_seconds: 60

    # --- Mermaid Agent (Python Tool based) ---
      - name: mermaid_pytool_agent_app # New distinct app name
        app_base_path: .
        app_module: solace_agent_mesh.agent.sac.app
        broker:
          <<: *broker_connection

        app_config:
          namespace: ${NAMESPACE}
          supports_streaming: true
          agent_name: "MermaidAgent" # Replaces the old MermaidAgent
          display_name: "Mermaid Diagram Generator"
          model: *planning_model # Or your preferred model (e.g., *general_model)
          instruction: |
            The MermaidAgent can generate PNG images from Mermaid diagram syntax.
            You will be provided with the Mermaid syntax as a string.
            Use the 'mermaid_diagram_generator' tool to create the PNG image.
            The tool accepts 'mermaid_syntax' (the diagram code) and an optional 'output_filename'.
            The generated image will be saved as a PNG artifact.
            Confirm completion by stating the name and version of the created artifact.
          tools:
            - tool_type: builtin
              tool_name: "mermaid_diagram_generator" # This is how the LLM will call the tool
            - tool_type: builtin-group
              group_name: "artifact_management"

          session_service:
            type: "memory"
            default_behavior: "PERSISTENT" # Or "RUN_BASED"

          artifact_service:
            type: "filesystem"
            base_path: "/tmp/samv2" # Or your preferred path
            artifact_scope: namespace
          artifact_handling_mode: "reference"
          enable_embed_resolution: true
          enable_artifact_content_instruction: true

          agent_card:
            description: "An agent that generates PNG images from Mermaid diagram syntax using a Python tool."
            defaultInputModes: ["text"] # Expects Mermaid syntax as text
            defaultOutputModes: ["text", "file"] # Confirms with text, outputs file artifact
            skills:
            - id: "mermaid_diagram_generator"
              name: "Mermaid Diagram Generator"
              description: "Generates a PNG image from Mermaid diagram syntax. Input: mermaid_syntax (string), output_filename (string, optional)."

          agent_card_publishing: { interval_seconds: 10 }
          agent_discovery: { enabled: false }
          inter_agent_communication:
            allow_list: []
            request_timeout_seconds: 60

    # --- Web Agent ---
      - name: web_agent_app
        app_base_path: .
        app_module: solace_agent_mesh.agent.sac.app
        broker:
          <<: *broker_connection

        app_config:
          namespace: ${NAMESPACE}
          supports_streaming: true
          agent_name: "WebAgent"
          display_name: "Web Agent"
          model: *planning_model # Or another appropriate model from shared_config.yaml
          instruction: |
            You are an agent that can fetch content from web URLs using the 'web_request' tool.
            You can make various types of HTTP requests (GET, POST, etc.) and include custom headers or a body.
            The tool will return the fetched content (HTML converted to Markdown, other text types as is, or raw binary data).
            You will then need to process this content based on the user's request.
            Always save useful fetched content as an artifact.

          tools:
            - tool_type: builtin
              tool_name: "web_request"
            - tool_type: builtin-group
              group_name: "artifact_management"

          session_service:
            type: "memory"
            default_behavior: "PERSISTENT"

          artifact_service:
            type: "filesystem"
            base_path: "/tmp/samv2"
            artifact_scope: namespace
          artifact_handling_mode: "reference"
          enable_embed_resolution: true
          enable_artifact_content_instruction: true

          agent_card:
            description: "An agent that fetches content from web URLs."
            defaultInputModes: ["text"]
            defaultOutputModes: ["text", "file"]
            skills:
              - id: "web_request"
                name: "Web Request"
                description: "Fetches content from a URL."

          agent_card_publishing: { interval_seconds: 10 }
          agent_discovery: { enabled: false }
          inter_agent_communication:
            allow_list: []
            request_timeout_seconds: 120 # Increased for potential web + LLM processing